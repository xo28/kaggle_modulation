{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os,random\n",
    "from keras.layers import Input,Reshape,ZeroPadding2D,Conv2D,Dropout,Flatten,Dense,Activation,MaxPooling2D,AlphaDropout,Conv1D,MaxPooling1D,BatchNormalization\n",
    "from keras import layers,regularizers\n",
    "import keras.models as Model\n",
    "from keras.regularizers import *\n",
    "from keras.optimizers import adam\n",
    "import keras\n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import pandas as pd\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 1024, 2)\n",
      "(20000, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "#loading data\n",
    "f = h5py.File(\"../modulation-prediction/data.hdf5\", 'r')\n",
    "X_train = np.array(f['train'])\n",
    "# X_train = X_train.reshape(X_train.shape[0], X_train.shape[2], X_train.shape[1])\n",
    "# X_train = X_train.reshape(X_train.shape[0], 2*X_train.shape[1]) # PCA\n",
    "print(X_train.shape)\n",
    "\n",
    "X_test = np.array(f['test'])\n",
    "# X_test = X_test.reshape(X_test.shape[0], X_test.shape[2], -1)\n",
    "# X_test = X_test.reshape(X_test.shape[0], 2*X_test.shape[1])\n",
    "print(X_test.shape)\n",
    "\n",
    "Y_train = pd.read_csv('../modulation-prediction/train_labels.csv').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "# pca = PCA(n_components = 1024).fit(X_train.reshape(X_train.shape[0], 2*X_train.shape[1]))\n",
    "# X_PCA = pca.tranform(X_train)\n",
    "# X_PCA = X_PCA.reshape(X_PCA.shape[0], 2, X_PCA.shape[1]/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_index = {\n",
    " 'FM': 0,\n",
    " 'OQPSK':1,\n",
    " 'BPSK':2,\n",
    " '8PSK':3,\n",
    " 'AM-SSB-SC':4,\n",
    " '4ASK':5,\n",
    " '16PSK':6,\n",
    " 'AM-DSB-SC':7, \n",
    " 'QPSK': 8, \n",
    " 'OOK':9\n",
    "}\n",
    "\n",
    "classnum = 10\n",
    "def classToIndex(catg):\n",
    "    return class_index[catg]\n",
    "\n",
    "#direct mapping, not one-hot\n",
    "def setToNum(dataset):\n",
    "    output = np.zeros((dataset.shape[0], 1),dtype = int)\n",
    "    for li, catg in enumerate(dataset[:,1]):\n",
    "        output[li] = classToIndex(catg)\n",
    "    return output         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_number = setToNum(Y_train)\n",
    "print(Y_number.dtype)\n",
    "\n",
    "Y_train = keras.utils.to_categorical(Y_number, num_classes=classnum, dtype='int64')\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model\"\"\"\n",
    "classes = [\n",
    " 'FM',\n",
    " 'OQPSK',\n",
    " 'BPSK',\n",
    " '8PSK',\n",
    " 'AM-SSB-SC',\n",
    " '4ASK',\n",
    " '16PSK',\n",
    " 'AM-DSB-SC',\n",
    " 'QPSK',\n",
    " 'OOK']\n",
    "data_format = 'channels_last'\n",
    "initializer = 'glorot_normal'\n",
    "\n",
    "def conv(Xm,Seq):\n",
    "    # 3*3 Conv\n",
    "    Xm = Conv1D(64, 3, padding='same', name=Seq+\"_conv\",activation = 'relu',kernel_initializer= initializer,data_format=data_format)(Xm)\n",
    "#     Xm = BatchNormalization()(Xm)\n",
    "    # ReLU\n",
    "    Xm = Activation(\"relu\")(Xm)\n",
    "#     Xm = Dropout(0.1)(Xm)\n",
    "    # MaxPooling\n",
    "    Xm = MaxPooling1D(pool_size=2, strides=2, padding='valid',data_format=data_format)(Xm)\n",
    "    return Xm\n",
    "\n",
    "\n",
    "in_shp = (1024,2)#X_train.shape[1:]   # each sample is [1024,2]\n",
    "#input layer\n",
    "Xm_input = Input(in_shp)\n",
    "Xm = Xm_input\n",
    "\n",
    "#Conv Stack\n",
    "Xm = conv(Xm,Seq = 'Conv1')   #shape:(64 * 512)\n",
    "Xm = conv(Xm,Seq = 'Conv2')   #shape:(64 * 256)\n",
    "Xm = conv(Xm,Seq = 'Conv3')   #shape:(64 * 128)\n",
    "Xm = conv(Xm,Seq = 'Conv4')   #shape:(64 * 64)\n",
    "Xm = Dropout(0.2)(Xm)\n",
    "Xm = conv(Xm,Seq = 'Conv5')   #shape:(64 * 32)\n",
    "Xm = Dropout(0.2)(Xm)\n",
    "Xm = conv(Xm,Seq = 'Conv6')   #shape:(64 * 16)\n",
    "Xm = Dropout(0.2)(Xm)\n",
    "Xm = conv(Xm,Seq = 'Conv7')   #shape:(64 * 8)\n",
    "Xm = Dropout(0.2)(Xm)\n",
    "#Full Con 1\n",
    "Xm = Flatten(data_format=data_format)(Xm)\n",
    "Xm = Dense(128, activation='selu', kernel_regularizer=l2(0.0), kernel_initializer=initializer, name=\"dense1\")(Xm)\n",
    "Xm = AlphaDropout(0.3)(Xm)\n",
    "#Full Con 2\n",
    "Xm = Dense(128, activation='selu', kernel_regularizer=l2(0.0), kernel_initializer=initializer, name=\"dense2\")(Xm)\n",
    "Xm = AlphaDropout(0.25)(Xm)\n",
    "#Full Con 3\n",
    "Xm = Dense(len(classes), activity_regularizer=l2(0.000),activation = 'softmax',kernel_initializer=initializer, name=\"dense3\")(Xm)\n",
    "# Xm = AlphaDropout(0.2)(Xm)\n",
    "#SoftMax\n",
    "# Xm = Activation('softmax')(Xm)\n",
    "#Create Model\n",
    "model = Model.Model(inputs=Xm_input,outputs=Xm)\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "# sgd = keras.optimizers.SGD(lr = 0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[keras.metrics.categorical_accuracy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "filepath = '../modulation-prediction/CNN_1d.h5'\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5,\n",
    "#                               patience=5, min_lr=0)\n",
    "hist = model.fit(X_train,\n",
    "    Y_train,\n",
    "    batch_size=32,\n",
    "    epochs=1000,\n",
    "    verbose=2,\n",
    "    validation_split = 0.2,\n",
    "    shuffle = True,\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=0, save_best_only=True, mode='auto'),\n",
    "#         keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=10, verbose=0, mode='auto'),\n",
    "#         reduce_lr\n",
    "    ])\n",
    "\n",
    "model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_class = {\n",
    " 0:'FM',\n",
    " 1:'OQPSK',\n",
    " 2:'BPSK',\n",
    " 3:'8PSK',\n",
    " 4:'AM-SSB-SC',\n",
    " 5:'4ASK',\n",
    " 6:'16PSK',\n",
    " 7:'AM-DSB-SC', \n",
    " 8:'QPSK', \n",
    " 9:'OOK',\n",
    "}\n",
    "\n",
    "# class to name\n",
    "def classToName(cls):\n",
    "    return index_class[cls]\n",
    "\n",
    "def onehotToNum(dataset):\n",
    "    output = np.array(np.argmax(dataset, axis = 1), ndmin = 2).T\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 10)\n",
      "Train Accuracy of the model over the 30000 train modulations: 65.36666666666666 %\n"
     ]
    }
   ],
   "source": [
    "train_Y_hat = model.predict(X_train, batch_size=1024)\n",
    "trainout = onehotToNum(train_Y_hat)\n",
    "total = 30000\n",
    "traincorrect = 0\n",
    "traincorrect += (trainout == Y_number).sum().item()\n",
    "\n",
    "print(train_Y_hat.shape)\n",
    "print('Train Accuracy of the model over the 30000 train modulations: {} %'.format(100 * traincorrect / total)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OOK' 'OOK' 'BPSK' ... 'AM-SSB-SC' 'AM-DSB-SC' 'OOK']\n"
     ]
    }
   ],
   "source": [
    "test_Y_hat = model.predict(X_test, batch_size=1024)\n",
    "testout = onehotToNum(test_Y_hat)\n",
    "\n",
    "predictionlist = testout.tolist()\n",
    "names = []\n",
    "\n",
    "for line in predictionlist:\n",
    "    names.append(classToName(line[0]))\n",
    "    \n",
    "outputs = np.asarray(names, dtype = str)\n",
    "print(outputs)\n",
    "categories = pd.DataFrame(outputs, columns = ['Category'])       \n",
    "categories.to_csv('outputs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
