{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pandas as pd\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30000, 1, 2, 1024])\n",
      "(30000, 2)\n"
     ]
    }
   ],
   "source": [
    "#loading data\n",
    "f = h5py.File(\"../modulation-prediction/data.hdf5\", 'r')\n",
    "X_train = np.array(f['train'])\n",
    "X_train = torch.from_numpy(X_train).reshape(X_train.shape[0],1,X_train.shape[2], X_train.shape[1])\n",
    "\n",
    "X_test = np.array(f['test'])\n",
    "X_test = torch.from_numpy(X_test).reshape(X_test.shape[0],1,X_test.shape[2], X_test.shape[1])\n",
    "\n",
    "Y_train = pd.read_csv('../modulation-prediction/train_labels.csv').to_numpy()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_index = {\n",
    " 'FM': 0,\n",
    " 'OQPSK':1,\n",
    " 'BPSK':2,\n",
    " '8PSK':3,\n",
    " 'AM-SSB-SC':4,\n",
    " '4ASK':5,\n",
    " '16PSK':6,\n",
    " 'AM-DSB-SC':7, \n",
    " 'QPSK': 8, \n",
    " 'OOK':9,\n",
    "}\n",
    "\n",
    "index_class = {\n",
    " 0:'FM',\n",
    " 1:'OQPSK',\n",
    " 2:'BPSK',\n",
    " 3:'8PSK',\n",
    " 4:'AM-SSB-SC',\n",
    " 5:'4ASK',\n",
    " 6:'16PSK',\n",
    " 7:'AM-DSB-SC', \n",
    " 8:'QPSK', \n",
    " 9:'OOK',\n",
    "}\n",
    "\n",
    "classnum = 10\n",
    "def classToIndex(catg):\n",
    "    return class_index[catg]\n",
    "\n",
    "#direct mapping, not one-hot\n",
    "def setToNum(dataset):\n",
    "    tensor = torch.zeros(dataset.shape[0], dtype = torch.long)\n",
    "    for li, catg in enumerate(dataset[:,1]):\n",
    "        tensor[li] = classToIndex(catg)\n",
    "    return tensor\n",
    "\n",
    "# class to name\n",
    "def classToName(cls):\n",
    "    return index_class[cls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "# sequence_length = 65\n",
    "# input_size = 2\n",
    "# hidden_size = 128\n",
    "num_epochs = 1000\n",
    "# num_layers = 1\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "Y_number = setToNum(Y_train)\n",
    "print(Y_number.shape)\n",
    "print(Y_number.dtype)\n",
    "\n",
    "# divide it into batch\n",
    "train_dataset = Data.TensorDataset(X_train,Y_number)\n",
    "validation_split = 0.2\n",
    "\n",
    "dataset_len = len(train_dataset)\n",
    "indices = list(range(dataset_len))\n",
    "\n",
    "# Randomly splitting indices:\n",
    "val_len = int(np.floor(validation_split * dataset_len))\n",
    "validation_idx = np.random.choice(indices, size=val_len, replace=False)\n",
    "train_idx = list(set(indices) - set(validation_idx))\n",
    "\n",
    "## Defining the samplers for each phase based on the random indices:\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "validation_sampler = SubsetRandomSampler(validation_idx)\n",
    "\n",
    "train_loader = Data.DataLoader(dataset=train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              sampler = train_sampler,\n",
    "                              shuffle=False)\n",
    "test_loader = Data.DataLoader(dataset = X_test,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False)\n",
    "validation_loader = Data.DataLoader(train_dataset, \n",
    "                                    batch_size=batch_size,\n",
    "                                    sampler=validation_sampler)\n",
    "data_loaders = {\"train\": train_loader, \"val\": validation_loader}\n",
    "data_lengths = {\"train\": len(train_idx), \"val\": val_len}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D Convolutional neural network \n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(2, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2, padding = 0))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(64,64, kernel_size=3, stride=1, padding=1,),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2, padding = 0))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2, padding = 0))\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2, padding = 0))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2, padding = 0))\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2, padding = 0))\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2, padding = 0))\n",
    "        \n",
    "        self.fc1 = nn.SELU()\n",
    "        self.fc2 = nn.SELU()\n",
    "        self.dropout = nn.AlphaDropout(p = 0.3)\n",
    "        self.fc1 = nn.Linear(64*8, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "model = ConvNet(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Convolutional neural network\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding = 1))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16,32, kernel_size=3, stride=1, padding=1,),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding = 1))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding = 1))\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding = 1))\n",
    "#         self.layer5 = nn.Sequential(\n",
    "#             nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2, padding = 1))\n",
    "#         self.layer6 = nn.Sequential(\n",
    "#             nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2, padding = 1))\n",
    "#         self.layer7 = nn.Sequential(\n",
    "#             nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2, padding = 1))\n",
    "        \n",
    "#         self.fc1 = nn.SELU()\n",
    "#         self.fc2 = nn.SELU()\n",
    "#         self.dropout = nn.AlphaDropout(p = 0.3)\n",
    "#         self.fc1 = nn.Linear(9*2*64, 128)\n",
    "        self.fc3 = nn.Linear(65*2*32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "#         out = self.layer5(out)\n",
    "#         out = self.layer6(out)\n",
    "#         out = self.layer7(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "#         out = self.fc1(out)\n",
    "#         out = self.fc2(out)\n",
    "#         out = self.dropout(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "model = ConvNet(num_classes)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay = 0.006)\n",
    "# scheduler = ReduceLROnPlateau(optimizer, 'min', factor = 0.5, patience=5)\n",
    "\n",
    "# Train the model\n",
    "# total_step = len(train_loader)\n",
    "bestmodel = 0\n",
    "best = 0\n",
    "for epoch in range(num_epochs):\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train(True)  # Set model to training mode\n",
    "        else:\n",
    "            model.train(False)  # Set model to evaluate mode\n",
    "        correct = 0\n",
    "        traincorrect = 0\n",
    "        total = val_len \n",
    "        total_step = len(data_loaders[phase])\n",
    "        for i, (samples, labels) in enumerate(data_loaders[phase]):\n",
    "        #       print(samples.shape)\n",
    "            samples = samples\n",
    "            labels = labels\n",
    "        #       print(labels.shape)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(samples)\n",
    "            loss = criterion(outputs, labels)\n",
    "                \n",
    "            # backward + optimize only if in training phase\n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                if (i+1) % 240 == 0:\n",
    "                    epoch_loss = 0\n",
    "                    model.eval()\n",
    "                    for trainsamples, trainlabels in train_loader:\n",
    "                        trainsamples = trainsamples\n",
    "                        trainlabels = trainlabels\n",
    "\n",
    "                        trainoutputs = model(trainsamples)\n",
    "                        epoch_loss += criterion(trainoutputs, trainlabels)\n",
    "                        _, trainpredicted = torch.max(trainoutputs.data, 1)\n",
    "                        traincorrect += (trainpredicted == trainlabels).sum().item()\n",
    "#                         scheduler.step(epoch_loss)\n",
    "                    print ('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}%' \n",
    "                        .format(epoch+1, num_epochs, i+1, total_step, loss.item(), 100*traincorrect/24000))\n",
    "\n",
    "            else:\n",
    "                _, valpredicted = torch.max(outputs.data, 1)\n",
    "                correct += (valpredicted == labels).sum().item()\n",
    "#                 scheduler.step(correct/total)\n",
    "                if (i+1) % 60 == 0:\n",
    "                    if(correct / total > best):\n",
    "                        best = correct / total\n",
    "                        bestmodel = copy.deepcopy(model) \n",
    "                    print ('Epoch [{}/{}], Validation Acc: {:.4f}%, Best Acc: {:.4f}%' \n",
    "                        .format(epoch+1, num_epochs, 100 *correct / total, best*100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train accuracy\n",
    "model = bestmodel\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    traincorrect = 0\n",
    "    total = 30000\n",
    "    \n",
    "    for trainsamples, labels in train_loader:\n",
    "        trainsamples = trainsamples\n",
    "        labels = labels\n",
    "        \n",
    "        trainoutputs = model(trainsamples)\n",
    "        _, trainpredicted = torch.max(trainoutputs.data, 1)\n",
    "        traincorrect += (trainpredicted == labels).sum().item()\n",
    "        \n",
    "    print('Train Accuracy of the model over the 30000 train modulations: {} %'.format(100 * traincorrect / total)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model = bestmodel\n",
    "model.eval()\n",
    "predictions = np.array([[999]])\n",
    "\n",
    "# print(predictions)\n",
    "with torch.no_grad():\n",
    "    for testsamples in test_loader:\n",
    "        testsamples = testsamples\n",
    "        \n",
    "        outputs = model(testsamples)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted = predicted.cpu().numpy().reshape(testsamples.shape[0],1)\n",
    "        predictions = np.vstack((predictions, predicted))\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionlist = predictions.tolist()\n",
    "names = []\n",
    "# print(len(predictionlist))\n",
    "for i in range(1,len(predictionlist)):\n",
    "    names.append(classToName(predictionlist[i][0]))\n",
    "    \n",
    "# print(names)\n",
    "outputs = np.asarray(names, dtype = str)\n",
    "# print(outputs)\n",
    "categories = pd.DataFrame(outputs, columns = ['Category'])       \n",
    "categories.to_csv('categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
